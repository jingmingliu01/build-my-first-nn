{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP+54SCOUNU11QfRtSYW8Eh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jingmingliu01/build-my-first-nn/blob/main/nn1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Load Data"
      ],
      "metadata": {
        "id": "cEIn2oR4J6Do"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "FI1Oe4CYJ9OI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load dataset, split into input and output"
      ],
      "metadata": {
        "id": "dxlY8GErKMkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=np.loadtxt('pima-indians-diabetes.csv',delimiter=',')\n",
        "X=dataset[:,0:8]\n",
        "y=dataset[:,8]"
      ],
      "metadata": {
        "id": "akaXKr0xKKTW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=torch.tensor(X,dtype=torch.float32)\n",
        "y=torch.tensor(y,dtype=torch.float32).reshape(-1,1)"
      ],
      "metadata": {
        "id": "UG6p8krRK_2W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Define Model"
      ],
      "metadata": {
        "id": "OvoqmAhGX7QR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# method1: use nn.Sequential\n",
        "model=nn.Sequential(\n",
        "    nn.Linear(8,12),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(12,8),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(8,1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32MEuyQIX-bt",
        "outputId": "fb5127b9-d817-41f5-b54c-8b3bd7e8c51e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=8, out_features=12, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=12, out_features=8, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=8, out_features=1, bias=True)\n",
            "  (5): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # method2: use DIY model\n",
        "# class PimaClassifier(nn.Module):\n",
        "#   def __init__(self):\n",
        "#     super().__init__()\n",
        "#     self.hidden1=nn.Linear(8,12)\n",
        "#     self.act1=nn.ReLU()\n",
        "#     self.hidden2=nn.Linear(12,8)\n",
        "#     self.act2=nn.ReLU()\n",
        "#     self.output=nn.Linear(8,1)\n",
        "#     self.act_output=nn.Sigmoid()\n",
        "\n",
        "#     def forward(self,x):\n",
        "#       x=self.act1(self.hidden1(x))\n",
        "#       x=self.act2(self.hidden2(x))\n",
        "#       x=self.act_output(self.output(x))\n",
        "#       return x\n",
        "\n",
        "# model=PimaClassifier()\n",
        "# print(model)"
      ],
      "metadata": {
        "id": "6icFZFGBY0Tr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Preparation for Training"
      ],
      "metadata": {
        "id": "51qbmlwEbzzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn=nn.BCELoss()\n",
        "optimizer=optim.Adam(model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "KYkhIhpSb33F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.Training a Model"
      ],
      "metadata": {
        "id": "Yicka0D_qcTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs=100\n",
        "batch_size=10\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  for i in range(0,len(X),batch_size):\n",
        "    Xbatch=X[i:i+batch_size]\n",
        "    y_pred=model(Xbatch)\n",
        "    ybatch=y[i:i+batch_size]\n",
        "    loss=loss_fn(y_pred,ybatch)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(f'Finished Epoch {epoch}, latest loss is {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yw57dHvqbS6",
        "outputId": "21bf2bb5-c5b6-4191-a911-f9ffc3533445"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Epoch 0, latest loss is 1.0060553550720215\n",
            "Finished Epoch 1, latest loss is 0.8935085535049438\n",
            "Finished Epoch 2, latest loss is 0.8139551281929016\n",
            "Finished Epoch 3, latest loss is 0.7661809325218201\n",
            "Finished Epoch 4, latest loss is 0.7322696447372437\n",
            "Finished Epoch 5, latest loss is 0.706889271736145\n",
            "Finished Epoch 6, latest loss is 0.6947529315948486\n",
            "Finished Epoch 7, latest loss is 0.6830228567123413\n",
            "Finished Epoch 8, latest loss is 0.673119306564331\n",
            "Finished Epoch 9, latest loss is 0.6640711426734924\n",
            "Finished Epoch 10, latest loss is 0.6598076820373535\n",
            "Finished Epoch 11, latest loss is 0.6562492847442627\n",
            "Finished Epoch 12, latest loss is 0.6512293815612793\n",
            "Finished Epoch 13, latest loss is 0.6466015577316284\n",
            "Finished Epoch 14, latest loss is 0.641308069229126\n",
            "Finished Epoch 15, latest loss is 0.6416739225387573\n",
            "Finished Epoch 16, latest loss is 0.6390330195426941\n",
            "Finished Epoch 17, latest loss is 0.6360775828361511\n",
            "Finished Epoch 18, latest loss is 0.6343545317649841\n",
            "Finished Epoch 19, latest loss is 0.6302147507667542\n",
            "Finished Epoch 20, latest loss is 0.6265684962272644\n",
            "Finished Epoch 21, latest loss is 0.6225060820579529\n",
            "Finished Epoch 22, latest loss is 0.612179160118103\n",
            "Finished Epoch 23, latest loss is 0.6047956347465515\n",
            "Finished Epoch 24, latest loss is 0.6007325649261475\n",
            "Finished Epoch 25, latest loss is 0.5781712532043457\n",
            "Finished Epoch 26, latest loss is 0.5660499334335327\n",
            "Finished Epoch 27, latest loss is 0.5579221248626709\n",
            "Finished Epoch 28, latest loss is 0.556005597114563\n",
            "Finished Epoch 29, latest loss is 0.55113685131073\n",
            "Finished Epoch 30, latest loss is 0.537211537361145\n",
            "Finished Epoch 31, latest loss is 0.5255387425422668\n",
            "Finished Epoch 32, latest loss is 0.5175312757492065\n",
            "Finished Epoch 33, latest loss is 0.5091832876205444\n",
            "Finished Epoch 34, latest loss is 0.5017713308334351\n",
            "Finished Epoch 35, latest loss is 0.49456727504730225\n",
            "Finished Epoch 36, latest loss is 0.49149075150489807\n",
            "Finished Epoch 37, latest loss is 0.4853357672691345\n",
            "Finished Epoch 38, latest loss is 0.48157867789268494\n",
            "Finished Epoch 39, latest loss is 0.47844013571739197\n",
            "Finished Epoch 40, latest loss is 0.47253134846687317\n",
            "Finished Epoch 41, latest loss is 0.46807029843330383\n",
            "Finished Epoch 42, latest loss is 0.46368396282196045\n",
            "Finished Epoch 43, latest loss is 0.4709436595439911\n",
            "Finished Epoch 44, latest loss is 0.4702858626842499\n",
            "Finished Epoch 45, latest loss is 0.4683960974216461\n",
            "Finished Epoch 46, latest loss is 0.46533092856407166\n",
            "Finished Epoch 47, latest loss is 0.4561525285243988\n",
            "Finished Epoch 48, latest loss is 0.45234981179237366\n",
            "Finished Epoch 49, latest loss is 0.44882068037986755\n",
            "Finished Epoch 50, latest loss is 0.45175474882125854\n",
            "Finished Epoch 51, latest loss is 0.4503549337387085\n",
            "Finished Epoch 52, latest loss is 0.44518861174583435\n",
            "Finished Epoch 53, latest loss is 0.44386133551597595\n",
            "Finished Epoch 54, latest loss is 0.4446639120578766\n",
            "Finished Epoch 55, latest loss is 0.44711750745773315\n",
            "Finished Epoch 56, latest loss is 0.4453434944152832\n",
            "Finished Epoch 57, latest loss is 0.4405485987663269\n",
            "Finished Epoch 58, latest loss is 0.4426109194755554\n",
            "Finished Epoch 59, latest loss is 0.4394244849681854\n",
            "Finished Epoch 60, latest loss is 0.43810927867889404\n",
            "Finished Epoch 61, latest loss is 0.43789204955101013\n",
            "Finished Epoch 62, latest loss is 0.4370075464248657\n",
            "Finished Epoch 63, latest loss is 0.4340478181838989\n",
            "Finished Epoch 64, latest loss is 0.4348843991756439\n",
            "Finished Epoch 65, latest loss is 0.43219247460365295\n",
            "Finished Epoch 66, latest loss is 0.43104007840156555\n",
            "Finished Epoch 67, latest loss is 0.42974579334259033\n",
            "Finished Epoch 68, latest loss is 0.4289129078388214\n",
            "Finished Epoch 69, latest loss is 0.42913544178009033\n",
            "Finished Epoch 70, latest loss is 0.42750123143196106\n",
            "Finished Epoch 71, latest loss is 0.42592039704322815\n",
            "Finished Epoch 72, latest loss is 0.42593473196029663\n",
            "Finished Epoch 73, latest loss is 0.4233315587043762\n",
            "Finished Epoch 74, latest loss is 0.4236258268356323\n",
            "Finished Epoch 75, latest loss is 0.4229815602302551\n",
            "Finished Epoch 76, latest loss is 0.42088207602500916\n",
            "Finished Epoch 77, latest loss is 0.42041435837745667\n",
            "Finished Epoch 78, latest loss is 0.42090386152267456\n",
            "Finished Epoch 79, latest loss is 0.4192628860473633\n",
            "Finished Epoch 80, latest loss is 0.41932618618011475\n",
            "Finished Epoch 81, latest loss is 0.4178050756454468\n",
            "Finished Epoch 82, latest loss is 0.4173922836780548\n",
            "Finished Epoch 83, latest loss is 0.4159408509731293\n",
            "Finished Epoch 84, latest loss is 0.4152153730392456\n",
            "Finished Epoch 85, latest loss is 0.41492924094200134\n",
            "Finished Epoch 86, latest loss is 0.41440021991729736\n",
            "Finished Epoch 87, latest loss is 0.41063183546066284\n",
            "Finished Epoch 88, latest loss is 0.4115014970302582\n",
            "Finished Epoch 89, latest loss is 0.4110090434551239\n",
            "Finished Epoch 90, latest loss is 0.40997371077537537\n",
            "Finished Epoch 91, latest loss is 0.4084678590297699\n",
            "Finished Epoch 92, latest loss is 0.4079938232898712\n",
            "Finished Epoch 93, latest loss is 0.405895471572876\n",
            "Finished Epoch 94, latest loss is 0.40583232045173645\n",
            "Finished Epoch 95, latest loss is 0.4046308696269989\n",
            "Finished Epoch 96, latest loss is 0.4031696915626526\n",
            "Finished Epoch 97, latest loss is 0.40287867188453674\n",
            "Finished Epoch 98, latest loss is 0.40077126026153564\n",
            "Finished Epoch 99, latest loss is 0.40030303597450256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.Evaluate the Model"
      ],
      "metadata": {
        "id": "JvjVdqPor_fG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_pred=model(X)\n",
        "\n",
        "accuracy=(y_pred.round()==y).float().mean()\n",
        "print(f\"Accuracy {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWY7PCO7sB7U",
        "outputId": "bed9e5a0-94fb-4b8b-cc12-dff52fec5f1d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.76953125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.Make prediction"
      ],
      "metadata": {
        "id": "KHz-kO3UyhXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  prediction=(model(X)>0.5).int()\n",
        "\n",
        "for i in range(5):\n",
        "  print((\"%s => %d(expected %d)\") % (X[i].tolist(),prediction[i],y[i]))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5MJmcqGykOz",
        "outputId": "f65efce9-3b57-4c36-9b2c-6742f60421de"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6.0, 148.0, 72.0, 35.0, 0.0, 33.599998474121094, 0.6269999742507935, 50.0] => 1(expected 1)\n",
            "[1.0, 85.0, 66.0, 29.0, 0.0, 26.600000381469727, 0.35100001096725464, 31.0] => 0(expected 0)\n",
            "[8.0, 183.0, 64.0, 0.0, 0.0, 23.299999237060547, 0.671999990940094, 32.0] => 1(expected 1)\n",
            "[1.0, 89.0, 66.0, 23.0, 94.0, 28.100000381469727, 0.16699999570846558, 21.0] => 0(expected 0)\n",
            "[0.0, 137.0, 40.0, 35.0, 168.0, 43.099998474121094, 2.2880001068115234, 33.0] => 1(expected 1)\n"
          ]
        }
      ]
    }
  ]
}